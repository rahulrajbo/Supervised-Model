{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahulrajbo/Supervised-Model/blob/main/Patients_Condition_Prediction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "4ir4V1m_NTc-"
      },
      "cell_type": "markdown",
      "source": [
        "# **• DOMAIN: Healthcare**"
      ]
    },
    {
      "metadata": {
        "id": "lWKCaNViNTdE"
      },
      "cell_type": "markdown",
      "source": [
        "# **• CONTEXT: Medical research university X is undergoing a deep research on patients with certain conditions.University has an internal AI team. Due to confidentiality the patient’s details and the conditions are masked by the client by providing different datasets to the AI team for developing a AIML model which can predict the condition of the patient depending on the received test results.**"
      ]
    },
    {
      "metadata": {
        "id": "gU-n1Z5rNTdG"
      },
      "cell_type": "markdown",
      "source": [
        "**• DATA DESCRIPTION: The data consists of biomechanics features of the patients according to their current\n",
        "conditions. Each patient is represented in the data set by six biomechanics attributes derived from the shape and\n",
        "orientation of the condition to their body part.**\n",
        "> **1. P_incidence**\n",
        "\n",
        "> **2. P_tilt**\n",
        "\n",
        "> **3. L_angle**\n",
        "\n",
        "> **4. S_slope**\n",
        "\n",
        "> **5. P_radius**\n",
        "\n",
        "> **6. S_degree**\n",
        "\n",
        "> **7. Class**"
      ]
    },
    {
      "metadata": {
        "id": "pDz2ahCINTdI"
      },
      "cell_type": "markdown",
      "source": [
        "1. **pelvic_incidence-P_incidence**\n",
        "2. **pelvic_tilt numeric-P_tilt**\n",
        "3. **lumbar_lordosis_angle-L_angle**\n",
        "4. **sacral_slope-S_slope**\n",
        "5. **pelvic_radius-P_radius**\n",
        "6. **degree_spondylolisthesis-S_degree**\n",
        "7. **class**"
      ]
    },
    {
      "metadata": {
        "id": "gkmFlYL1NTdJ"
      },
      "cell_type": "markdown",
      "source": [
        "# Importing Necessary Packages"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "is-srsXINTdK"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy import stats\n",
        "%matplotlib inline\n",
        "sns.set_style('darkgrid')\n",
        "%matplotlib inline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from scipy.stats import zscore\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import model_selection\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "38R8EM5XNTdM"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Import and warehouse data:"
      ]
    },
    {
      "metadata": {
        "id": "6WzyEPcDNTdM"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset 1**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "TWMjXmsrNTdM"
      },
      "cell_type": "code",
      "source": [
        "df1=pd.read_csv('../input/patients-condition/Part1 - Normal.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW0vOV9iNTdN"
      },
      "cell_type": "markdown",
      "source": [
        "**Checking First 5 Rows**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "bwOP4Y5MNTdN"
      },
      "cell_type": "code",
      "source": [
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8SI3C8dNTdN"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of the dataset**"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "q5I2ancWNTdO"
      },
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AMWNDwReNTdO"
      },
      "cell_type": "markdown",
      "source": [
        "**We have 7 columns and 100 rows**"
      ]
    },
    {
      "metadata": {
        "id": "_eEKMze2NTdO"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset-2**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "DQ44RzDjNTdP"
      },
      "cell_type": "code",
      "source": [
        "df2=pd.read_csv('../input/patients-condition/Part1 - Type_H.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lt-3zqKfNTdP"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of the dataset**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "zmUNnRkGNTdQ"
      },
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XAljqtTNTdQ"
      },
      "cell_type": "markdown",
      "source": [
        "**Checking First 5 Rows**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "02ecCFz2NTdQ"
      },
      "cell_type": "code",
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eu0RBM6PNTdR"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of the dataset**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "-20G_zsqNTdR"
      },
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p1kDaN73NTdS"
      },
      "cell_type": "markdown",
      "source": [
        "**We have 7 columns and 60 rows**"
      ]
    },
    {
      "metadata": {
        "id": "fJGcjQazNTdS"
      },
      "cell_type": "markdown",
      "source": [
        "**Dataset-3**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "hEnjY0PvNTdS"
      },
      "cell_type": "code",
      "source": [
        "df3=pd.read_csv('../input/patients-condition/Part1 - Type_S.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-3MbYnv_NTdT"
      },
      "cell_type": "markdown",
      "source": [
        "**Checking First 5 Rows**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "mgbyfj5UNTdT"
      },
      "cell_type": "code",
      "source": [
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1IUsKw23NTdT"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of the dataset**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_HRl3qm4NTdU"
      },
      "cell_type": "code",
      "source": [
        "df3.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LTNZ9FXvNTdU"
      },
      "cell_type": "markdown",
      "source": [
        "**We have 7 columns and 150 rows**"
      ]
    },
    {
      "metadata": {
        "id": "9Sc4qIQ1NTdV"
      },
      "cell_type": "markdown",
      "source": [
        "**Final Dataframe**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Syb00IF-NTdV"
      },
      "cell_type": "code",
      "source": [
        "df=df1.append([df2,df3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vj6ZNP3VNTdV"
      },
      "cell_type": "markdown",
      "source": [
        "**Shape of the dataset**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Zarqy9joNTdW"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jnoS0eqkNTdW"
      },
      "cell_type": "markdown",
      "source": [
        "**Final Dataset have 7 columns and 310 rows**"
      ]
    },
    {
      "metadata": {
        "id": "Mdpr8CxVNTdX"
      },
      "cell_type": "markdown",
      "source": [
        "# 2. Data cleansing:"
      ]
    },
    {
      "metadata": {
        "id": "mgh494ZXNTdX"
      },
      "cell_type": "markdown",
      "source": [
        "**Information about the data**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "UfCKpemwNTdX"
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LVIMusnTNTdY"
      },
      "cell_type": "markdown",
      "source": [
        "**Checking Datatypes**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Dm5Qo8j8NTdZ"
      },
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sPP1Jty4NTda"
      },
      "cell_type": "markdown",
      "source": [
        "**There is no junk values in the dataset**\n",
        "\n",
        "**Class is object we need to change the datatype of this column**"
      ]
    },
    {
      "metadata": {
        "id": "7WFzmJgeNTda"
      },
      "cell_type": "markdown",
      "source": [
        "**Missing Value Check**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "4CUq_3lpNTda"
      },
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HrVTP-FhNTdb"
      },
      "cell_type": "markdown",
      "source": [
        "**There is no missing value in the dataset**"
      ]
    },
    {
      "metadata": {
        "id": "Fm6c1C_wNTdb"
      },
      "cell_type": "markdown",
      "source": [
        "**Target Variable:**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OKQW2kl7NTde"
      },
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1OQ8Nzy_NTdf"
      },
      "cell_type": "markdown",
      "source": [
        "**Here tp_s and Type_S, Normal and Nrmal,Type_H and type_ h represents same class.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9ueeIbouNTdg"
      },
      "cell_type": "code",
      "source": [
        "df.loc[df['Class']=='tp_s','Class']='Type_S'\n",
        "df.loc[df['Class']=='Nrmal','Class']='Normal'\n",
        "df.loc[df['Class']=='type_h','Class']='Type_H'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "eil64hjLNTdg"
      },
      "cell_type": "code",
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "9DI4gzRKNTdh"
      },
      "cell_type": "code",
      "source": [
        "df['Class']=df['Class'].astype('category') #changing to category datatype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Yz5b2uKWNTdh"
      },
      "cell_type": "code",
      "source": [
        "df['Class'].nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z7AzrGejNTdi"
      },
      "cell_type": "markdown",
      "source": [
        "**Here we have three different class in our dataset**"
      ]
    },
    {
      "metadata": {
        "id": "VSMF5znoNTdi"
      },
      "cell_type": "markdown",
      "source": [
        "# 3.Data Analysis & Visulaization"
      ]
    },
    {
      "metadata": {
        "id": "mrUEmcLANTdj"
      },
      "cell_type": "markdown",
      "source": [
        "**5 Point Summary**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Z4Y2yXf8NTdj"
      },
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Jcbisx6NTdk"
      },
      "cell_type": "markdown",
      "source": [
        "**P_incidence:**\n",
        "\n",
        ">  **Mean and Median are nearly equal .**\n",
        "\n",
        "> **Distribution might be normal. we have 75 % of values are less than 72 but maxiumum value is 129**\n",
        "\n",
        "**P_tilt:**\n",
        "\n",
        "> **Mean and median are nearly equal.**\n",
        "\n",
        "> **Distribution might be normal.**\n",
        "\n",
        "> **It contains negative values**\n",
        "\n",
        "> **75 % of values are less than 22 but maximum value is 49 so there might be little right skewness**\n",
        "\n",
        "**L_angle:**\n",
        "\n",
        "> **Mean and Median are nearly equal. There is no  deviation.**\n",
        "\n",
        "> **Distribution might be normal**\n",
        "\n",
        "> **There might be few outliers because of the maximum value**\n",
        "\n",
        "**S_slope:**\n",
        "\n",
        "> **Mean and Median are nearly equal.**\n",
        "\n",
        "> **Towards the end there is little devation. 75% of values are lesser than 52 but maximum value is 121.**\n",
        "\n",
        "**P_radius:**\n",
        "\n",
        "> **Distribution might be normal.**\n",
        "\n",
        "> **There is no much Deviation.**\n",
        "\n",
        "**S_Degree:**\n",
        "\n",
        "> **Mean is greater than Median so there might be right skewness in the data .**\n",
        "\n",
        "> **We can see 75% of values are less than 41 but maximum value is 418 so there is obvious outliers in the data.**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "KpONx9frNTdk"
      },
      "cell_type": "markdown",
      "source": [
        "# **Univariate Analysis**"
      ]
    },
    {
      "metadata": {
        "id": "1IVWKq_ONTdl"
      },
      "cell_type": "markdown",
      "source": [
        "**Distribution and outlier analysis of numerical variables**"
      ]
    },
    {
      "metadata": {
        "id": "2VygEjotNTdl"
      },
      "cell_type": "markdown",
      "source": [
        "**P_incidence**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "0NBcMvaZNTdl"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'P_incidence', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['P_incidence'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['P_incidence'],25),np.percentile(df['P_incidence'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['P_incidence'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in P_incidence: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p__DRa08NTdm"
      },
      "cell_type": "markdown",
      "source": [
        "> **Normality is maintained with very less extreme values**\n",
        "\n",
        "> **We can see three outliers exists in the column**"
      ]
    },
    {
      "metadata": {
        "id": "rDOf_IIZNTdm"
      },
      "cell_type": "markdown",
      "source": [
        "**P_tilt**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "FLLdBsRTNTdm"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'P_tilt', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['P_tilt'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['P_tilt'],25),np.percentile(df['P_tilt'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['P_tilt'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in P_tilt: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OEK2dFEgNTdn"
      },
      "cell_type": "markdown",
      "source": [
        "> **Data is Normally distributed and we can see one peakness in the center**\n",
        "\n",
        "> **It is has little skewness towards right side**\n",
        "\n",
        "> **We can see one outlier in negative end and few outliers in positive end.**"
      ]
    },
    {
      "metadata": {
        "id": "4yb2-axUNTdn"
      },
      "cell_type": "markdown",
      "source": [
        "**L_angle**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "7ECWuYbYNTdo"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'L_angle', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['L_angle'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['L_angle'],25),np.percentile(df['L_angle'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['L_angle'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in L_angle: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6LI-CtcONTdo"
      },
      "cell_type": "markdown",
      "source": [
        "> **It is Normally distributed**\n",
        "\n",
        "> **Little right skewness because of one outlier**"
      ]
    },
    {
      "metadata": {
        "id": "so11GBrPNTdo"
      },
      "cell_type": "markdown",
      "source": [
        "**S_slope**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "5k0071CbNTdp"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'S_slope', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['S_slope'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['S_slope'],25),np.percentile(df['S_slope'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['S_slope'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in S_slope: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OsR4ujWONTdp"
      },
      "cell_type": "markdown",
      "source": [
        "> **There is right skewness due to one outlier**"
      ]
    },
    {
      "metadata": {
        "id": "LXd32co3NTdp"
      },
      "cell_type": "markdown",
      "source": [
        "**P_radius**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "pmFDa_NINTdq"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'P_radius', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['P_radius'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['P_radius'],25),np.percentile(df['P_radius'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['P_radius'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in P_radius: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OjYGs5LHNTdq"
      },
      "cell_type": "markdown",
      "source": [
        "> **Data is normally distributed**\n",
        "\n",
        "> **We can see outliers at both the ends.**"
      ]
    },
    {
      "metadata": {
        "id": "vlsZNyWrNTdq"
      },
      "cell_type": "markdown",
      "source": [
        "**S_Degree**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "8LsF-DnJNTdq"
      },
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(1, 2, figsize=(17,7))\n",
        "sns.boxplot(x = 'S_Degree', data=df,  orient='h' , ax=axes[1],color='Green')\n",
        "sns.distplot(df['S_Degree'],  ax=axes[0],color='Green')\n",
        "axes[0].set_title('Distribution plot')\n",
        "axes[1].set_title('Box plot')\n",
        "plt.show()\n",
        "#checking count of outliers.\n",
        "q25,q75=np.percentile(df['S_Degree'],25),np.percentile(df['S_Degree'],75)\n",
        "IQR=q75-q25\n",
        "Threshold=IQR*1.5\n",
        "lower,upper=q25-Threshold,q75+Threshold\n",
        "Outliers=[i for i in df['S_Degree'] if i < lower or i > upper]\n",
        "print('{} Total Number of outliers in S_Degree: {}'.format('\\033[1m',len(Outliers)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sryCRJkWNTdr"
      },
      "cell_type": "markdown",
      "source": [
        "> **There is Positive Skewness in the data**\n",
        "\n",
        "> **Hugely affected by Outliers**"
      ]
    },
    {
      "metadata": {
        "id": "8UyCazAJNTdr"
      },
      "cell_type": "markdown",
      "source": [
        "**Distribution of Target Variable**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "wCgQhJykNTdr"
      },
      "cell_type": "code",
      "source": [
        "f,axes=plt.subplots(1,2,figsize=(17,7))\n",
        "df['Class'].value_counts().plot.pie(autopct='%1.1f%%',ax=axes[0])\n",
        "sns.countplot('Class',data=df,ax=axes[1])\n",
        "axes[0].set_title('Response Variable Pie Chart')\n",
        "axes[1].set_title('Response Variable Bar Graph')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jXbi28lzNTds"
      },
      "cell_type": "markdown",
      "source": [
        "**Type_S variable has 48.4% of total values followed by Normal and Type_H**"
      ]
    },
    {
      "metadata": {
        "id": "hCAIpXKYNTds"
      },
      "cell_type": "markdown",
      "source": [
        " # **Bi Variate Analysis**"
      ]
    },
    {
      "metadata": {
        "id": "XTZO6CgLNTds"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs P_incidence**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PbnTl9NpNTdt"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='P_incidence', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9tEkAWPDNTdt"
      },
      "cell_type": "markdown",
      "source": [
        "> **P_Incidence Value is larger for Type_S Class. We can see some extreme values as well**\n",
        "\n",
        "> **Normal Value is slightly higher than Type_H**"
      ]
    },
    {
      "metadata": {
        "id": "CbbAGzthNTdt"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs P_tilt**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "q1Kg-b6gNTdt"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='P_tilt', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1MHaX0CUNTdu"
      },
      "cell_type": "markdown",
      "source": [
        "> **Mean of Type_S is slightly higher than rest two**\n",
        "\n",
        "> **Few cases Normal and Type_H also has huge values**"
      ]
    },
    {
      "metadata": {
        "id": "R9CFGNJJNTdu"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs L_angle**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "29wBchaYNTdu"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='L_angle', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FqXutt4vNTdu"
      },
      "cell_type": "markdown",
      "source": [
        "> **L_Angle has higher value for Type_S Class**\n",
        "\n",
        ">**We can see Normal class has higher values compared to type_H class**\n",
        "\n",
        "> **Each class contains one outlier**"
      ]
    },
    {
      "metadata": {
        "id": "Ud7CNqRxNTdv"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs S_slope**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "HsJOCIdTNTdv"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='S_slope', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yWQjwn5NNTdv"
      },
      "cell_type": "markdown",
      "source": [
        "> **S_slope has huge values for Type_S class**\n",
        "\n",
        ">**Normal class has high s_slope compared to Type_H**"
      ]
    },
    {
      "metadata": {
        "id": "DLcsc55eNTdv"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs P_radius**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "t1YItfz0NTdw"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='P_radius', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ATusnF-JNTdw"
      },
      "cell_type": "markdown",
      "source": [
        "> **We can see P_radius value is more for Normal Class**\n",
        "\n",
        "> **There is some extreme values for Type_s class**\n",
        "\n",
        "> **All classes has higher and lower Value**"
      ]
    },
    {
      "metadata": {
        "id": "f0ICF2slNTdw"
      },
      "cell_type": "markdown",
      "source": [
        "**Class vs S_Degree**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "t7hhNZlkNTdw"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "sns.boxplot(x='Class', y='S_Degree', data= df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I53re39lNTdx"
      },
      "cell_type": "markdown",
      "source": [
        "> **S_Degree has extreme values for type_S Class**\n",
        "\n",
        ">**Few Normal class also has huge values for S_Degree**"
      ]
    },
    {
      "metadata": {
        "id": "xC1xpWxNNTdx"
      },
      "cell_type": "markdown",
      "source": [
        "# **Multivariate Analysis**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "3TA9sSknNTdx"
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tRHckalaNTdy"
      },
      "cell_type": "markdown",
      "source": [
        "**Pair Plot of independent Variables**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "lJk5yFjQNTdy"
      },
      "cell_type": "code",
      "source": [
        "sns.pairplot(df)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlFGol_PNTdy"
      },
      "cell_type": "markdown",
      "source": [
        "> **Along the diagonal we can see the distribution of individual variable**\n",
        "\n",
        "> **P_incidence has  postive realtionship with all variables except P_radius. Relationship is higher for S_slope and L_angle**\n",
        "\n",
        "> **P_tilt has Higher Relationship with P_incidence and L_angle.There is no Relationship with s_slope and p_radius**\n",
        "\n",
        "> **L_angle has postive Relationship with p_tilt,s_slope and s_degree. It has no Relationship with P_radius**\n",
        "\n",
        "> **s_slope has positive Relationship with L_angle and s_degree**\n",
        "\n",
        "> **p_radius has no Relationship with s_degree,p_tilt,l_angle.**\n",
        "\n",
        "> **S_degree has no strong positive Relationship with any of the variables.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "ootFLWdQNTdz"
      },
      "cell_type": "code",
      "source": [
        "sns.pairplot(df,hue='Class')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aoHbsgW8NTdz"
      },
      "cell_type": "markdown",
      "source": [
        "> **Along the diagonal we can see distribution of variable for three claases are not same.We can prove that statistically as well**\n",
        "\n",
        "> **It is evident that type_s class is more compared to other two**\n",
        "\n",
        "> **Normal class has higher values compared to Type_H**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "fo0Jo4VrNTdz"
      },
      "cell_type": "code",
      "source": [
        "class_summary=df.groupby('Class') #getting mean values of each class for all independent variables\n",
        "class_summary.mean().reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RcyV2WWANTdz"
      },
      "cell_type": "markdown",
      "source": [
        "**It is clear that s_Degree of Type_S contains larger values.**\n"
      ]
    },
    {
      "metadata": {
        "id": "SmfjjSrpNTd0"
      },
      "cell_type": "markdown",
      "source": [
        "# **Hypotesis Testing**"
      ]
    },
    {
      "metadata": {
        "id": "05NdQviUNTd0"
      },
      "cell_type": "markdown",
      "source": [
        "# Is the distribution of independent variables across normal,type_H and type_s, the same?"
      ]
    },
    {
      "metadata": {
        "id": "Z9c4vviyNTd0"
      },
      "cell_type": "markdown",
      "source": [
        "**Here we are using one-way anova to do statistical test.**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "I37QXol3NTd0"
      },
      "cell_type": "code",
      "source": [
        "col=['P_incidence','P_tilt','L_angle','S_slope','P_radius','S_Degree']\n",
        "for i in col:\n",
        "    print('{} Ho: Class types does not affect the {}'.format('\\033[1m',i))\n",
        "    print('\\n')\n",
        "    print('{} H1: Class types affect the {}'.format('\\033[1m',i))\n",
        "    print('\\n')\n",
        "    df_normal=df[df.Class=='Normal'][i]\n",
        "    df_typeH=df[df.Class=='Type_H'][i]\n",
        "    df_typeS=df[df.Class=='Type_S'][i]\n",
        "    f_stats,p_value=stats.f_oneway(df_normal,df_typeH,df_typeS)\n",
        "    print('{} F_stats: {}'.format('\\033[1m',f_stats))\n",
        "    print('{} p_value: {}'.format('\\033[1m',p_value))\n",
        "    if p_value < 0.05:  # Setting our significance level at 5%\n",
        "        print('{} Rejecting Null Hypothesis.Class types has efect on {}'.format('\\033[1m',i))\n",
        "    else:\n",
        "        print('{} Fail to Reject Null Hypothesis.Class types has no effect on {}'.format('\\033[1m',i))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DysG6puxNTd1"
      },
      "cell_type": "markdown",
      "source": [
        "**We can see class type affects each and every independent variables**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "aRtd0FuDNTd1"
      },
      "cell_type": "code",
      "source": [
        "plt.figure(dpi = 120,figsize= (5,4))\n",
        "mask = np.triu(np.ones_like(df.corr()))\n",
        "sns.heatmap(df.corr(),mask = mask, fmt = \".2f\",annot=True,lw=1,cmap = 'plasma')\n",
        "plt.yticks(rotation = 0)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BduKi68wNTd1"
      },
      "cell_type": "markdown",
      "source": [
        "**Correlation between s_degree and p_incidence have high correlation.**\n",
        "\n",
        "**S_degree and p_radius has negative correlation**"
      ]
    },
    {
      "metadata": {
        "id": "8I8YKPJYNTd2"
      },
      "cell_type": "markdown",
      "source": [
        "# 4. Data Pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "Xt3oawruNTd2"
      },
      "cell_type": "markdown",
      "source": [
        "# **Outlier Analysis**"
      ]
    },
    {
      "metadata": {
        "id": "2JAxH-1lNTd2"
      },
      "cell_type": "markdown",
      "source": [
        "**As we have seen in our EDA we have very less outliers which needs to be handled**"
      ]
    },
    {
      "metadata": {
        "id": "vyRnSvzgNTd2"
      },
      "cell_type": "markdown",
      "source": [
        "**We are imputing outiers with mean**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "sbIk8vEgNTd3"
      },
      "cell_type": "code",
      "source": [
        "for c in col:\n",
        "    #getting upper lower quartile values\n",
        "    q25,q75=np.percentile(df[c],25),np.percentile(df[c],75)\n",
        "    IQR=q75-q25\n",
        "    Threshold=IQR*1.5\n",
        "    lower,upper=q25-Threshold,q75+Threshold\n",
        "    Outliers=[i for i in df[c] if i < lower or i > upper]\n",
        "    print('{} Total Number of outliers in {} Before Imputing : {}'.format('\\033[1m',c,len(Outliers)))\n",
        "    print('\\n')\n",
        "    #taking mean of a column without considering outliers\n",
        "    df_include = df.loc[(df[c] >= lower) & (df[c] <= upper)]\n",
        "    mean=int(df_include[c].mean())\n",
        "    print('{} Mean of {} is {}'.format('\\033[1m',c,mean))\n",
        "    print('\\n')\n",
        "    #imputing outliers with mean\n",
        "    df[c]=np.where(df[c]>upper,mean,df[c])\n",
        "    df[c]=np.where(df[c]<lower,mean,df[c])\n",
        "    Outliers=[i for i in df[c] if i < lower or i > upper]\n",
        "    print('{} Total Number of outliers in {} After Imputing : {}'.format('\\033[1m',c,len(Outliers)))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6cDmGvLNTd6"
      },
      "cell_type": "markdown",
      "source": [
        "> **We have imputed all outliers with mean value**"
      ]
    },
    {
      "metadata": {
        "id": "AR9ZhOauNTd6"
      },
      "cell_type": "markdown",
      "source": [
        "# **Encoding Target Variable**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "2JbtZ0AGNTd6"
      },
      "cell_type": "code",
      "source": [
        "le=LabelEncoder()\n",
        "df['Class']=le.fit_transform(df['Class'])\n",
        "df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNZx3GMFNTd7"
      },
      "cell_type": "markdown",
      "source": [
        "**Normal: 0**\n",
        "\n",
        "**Type_H: 1**\n",
        "\n",
        "**Type_S: 2**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "cPm09fTyNTd7"
      },
      "cell_type": "code",
      "source": [
        "df['Class']=df['Class'].astype('category') #changing datatype to category."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bA-vvjKCNTd8"
      },
      "cell_type": "markdown",
      "source": [
        "# **Checking on Target Imbalance**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "_KRRvdGLNTd8"
      },
      "cell_type": "code",
      "source": [
        "f,axes=plt.subplots(1,2,figsize=(17,7))\n",
        "df['Class'].value_counts().plot.pie(autopct='%1.1f%%',ax=axes[0])\n",
        "sns.countplot('Class',data=df,ax=axes[1],order=[2,0,1])\n",
        "axes[0].set_title('Response Variable Pie Chart')\n",
        "axes[1].set_title('Response Variable Bar Graph')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bouzrT8LNTd8"
      },
      "cell_type": "markdown",
      "source": [
        "**We have imbalanced target variable**\n",
        "\n",
        "**Every class is not equally distributed.**\n",
        "\n",
        "**48% of data is occupied by Type_S**\n",
        "\n",
        "**When you have imbalance dataset model does not learn about less distributed classes. This gives\n",
        "poor performance in unseen data**"
      ]
    },
    {
      "metadata": {
        "id": "doVdycfMNTd9"
      },
      "cell_type": "markdown",
      "source": [
        "# Train - Test Split"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "m7PIXxaTNTd9"
      },
      "cell_type": "code",
      "source": [
        "# Arrange data into independent variables and dependent variables\n",
        "X=df.drop(columns='Class')\n",
        "y=df['Class'] #target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "H14rJf5tNTd9"
      },
      "cell_type": "code",
      "source": [
        "X.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WGLI_mfbNTd-"
      },
      "cell_type": "markdown",
      "source": [
        "# **Scaling Independent Variables**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "LPVTi31ZNTd-"
      },
      "cell_type": "code",
      "source": [
        "X_Scaled=X.apply(zscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "CsfIPEj-NTd_"
      },
      "cell_type": "code",
      "source": [
        "X_Scaled.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSqwH4wYNTd_"
      },
      "cell_type": "markdown",
      "source": [
        "> **We have scaled independent variables to corresponding z-score.**\n",
        "\n",
        "> **We can see Mean becomes close to zero and Standard Deviation becomes 1**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "OnYciTqENTeA"
      },
      "cell_type": "code",
      "source": [
        "# Split X and y into training and test set in 70:30 ratio\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tXsTqxOxNTeA"
      },
      "cell_type": "markdown",
      "source": [
        "# 5. Model training, testing and tuning"
      ]
    },
    {
      "metadata": {
        "id": "C2I4gQjDNTeA"
      },
      "cell_type": "markdown",
      "source": [
        "# **KNN Classifier**"
      ]
    },
    {
      "metadata": {
        "id": "lRzRsoTcNTeB"
      },
      "cell_type": "markdown",
      "source": [
        "**Basic Model**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "BfHblYLINTeB"
      },
      "cell_type": "code",
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors= 5 , metric = 'euclidean' ) #Building knn with 5 neighbors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1TmTqpaqNTeB"
      },
      "cell_type": "code",
      "source": [
        "KNN.fit(X_train, y_train)\n",
        "predicted_labels = KNN.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JKUkrMIhNTeC"
      },
      "cell_type": "markdown",
      "source": [
        "# Classification Accuracy"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "Ty5kQDBtNTeC"
      },
      "cell_type": "code",
      "source": [
        "print('Accuracy on Training data:',KNN.score(X_train, y_train) )\n",
        "print('Accuracy on Test data:',KNN.score(X_test, y_test) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QjQ08CkeNTeC"
      },
      "cell_type": "markdown",
      "source": [
        "> **Training Acuracy is 0.89 and Testing Accuracy is 0.77. Performance is less in test data.**\n",
        "\n",
        "> **This is due to overfitting of data**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "PkROpYOPNTeC"
      },
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, predicted_labels, labels=[0, 1,2])\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in [\"Normal\",\"Type_H\",\"Type_S\"]],\n",
        "                  columns = [i for i in [\"Normal\",\"Type_H\",\"Type_S\"]])\n",
        "plt.figure(figsize = (7,5))\n",
        "sns.heatmap(df_cm, annot=True ,fmt='g')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m_a4gJJbNTeD"
      },
      "cell_type": "markdown",
      "source": [
        "> **Our model predicts Type_S correctly most of the time. Only two misclassification on this class**\n",
        "\n",
        "> **Misclassification of labels are more when predicting normal class**"
      ]
    },
    {
      "metadata": {
        "id": "1ZONmeu9NTeD"
      },
      "cell_type": "markdown",
      "source": [
        "# Classification Report"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "IZE0GQRJNTeD"
      },
      "cell_type": "code",
      "source": [
        "print(\"classification  Matrix:\\n\",classification_report(y_test,predicted_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MfkpWb3ENTeE"
      },
      "cell_type": "markdown",
      "source": [
        "> **Precision for Normal class: It tells,out of all predicted normal class what fraction are predicted correctly**\n",
        "\n",
        "> **Recall(sensitivity or TPR) for Normal class: Out of all actual Normal class how much fraction we identified correctly**\n",
        "\n",
        "> **class 0 predicted correctly for 68% of time. similary for class 1 48% and class 2 98%**\n",
        "\n",
        "> **By F1 score we can say that precison and recall is balanced for class 0 by 60% and for class 1 by 56 %**\n",
        "\n",
        "> **We have maximum F1 score for class 2.**"
      ]
    },
    {
      "metadata": {
        "id": "P3EhgGEmNTeE"
      },
      "cell_type": "markdown",
      "source": [
        "# **Finding best K value**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "z02UHhrCNTeE"
      },
      "cell_type": "code",
      "source": [
        "train_score=[]\n",
        "test_score=[]\n",
        "for k in range(1,51):\n",
        "    KNN = KNeighborsClassifier(n_neighbors= k , metric = 'euclidean' )\n",
        "    KNN.fit(X_train, y_train)\n",
        "    train_score.append(KNN.score(X_train, y_train))\n",
        "    test_score.append(KNN.score(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "raP5bXWANTeE"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,51),train_score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCsrg31hNTeF"
      },
      "cell_type": "markdown",
      "source": [
        "> **Here training accuracy decreases when increase k value**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "1-lVx9E6NTeF"
      },
      "cell_type": "code",
      "source": [
        "plt.plot(range(1,51),test_score)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Czud6VbWNTeF"
      },
      "cell_type": "markdown",
      "source": [
        "> **The maximum accuracy occures when k is less than 20.**\n",
        "\n",
        "> **We will fix k value as less than 20.**"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "trusted": true,
        "id": "W7SuOWUQNTeG"
      },
      "cell_type": "code",
      "source": [
        "k=[1,3,5,7,9,11,13,15,17,19]\n",
        "for i in k:\n",
        "    KNN = KNeighborsClassifier(n_neighbors=i, metric = 'euclidean' ) #Building knn with 5 neighbors\n",
        "    KNN.fit(X_train, y_train)\n",
        "    predicted_labels = KNN.predict(X_test)\n",
        "    print('Accuracy on Training data for k {} is {}:'.format(i,KNN.score(X_train, y_train)))\n",
        "    print('Accuracy on Test data for k {} is {}:'.format(i,KNN.score(X_test, y_test)))\n",
        "    print(\"classification  Matrix:\\n\",classification_report(y_test,predicted_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gUQc0nwYNTeG"
      },
      "cell_type": "markdown",
      "source": [
        "> **For K=13 we have balanced train and test error**\n",
        "\n",
        "> **we can use k value as 13 because when we increase this value the precision becomes100% for class 2**"
      ]
    },
    {
      "metadata": {
        "id": "DzJU8JjbNTeH"
      },
      "cell_type": "markdown",
      "source": [
        "# K-Fold CV for finding best model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "SoDW_nuONTeH"
      },
      "cell_type": "code",
      "source": [
        "LR_model=LogisticRegression()\n",
        "KNN_model=KNeighborsClassifier(n_neighbors=13)\n",
        "GN_model=GaussianNB()\n",
        "svc_model_linear = SVC(kernel='linear',C=1,gamma=.6)\n",
        "svc_model_rbf = SVC(kernel='rbf',degree=2,C=.009)\n",
        "svc_model_poly  = SVC(kernel='poly',degree=2,gamma=0.1,C=.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "id": "QOBTHZCrNTeI"
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LR_model))\n",
        "models.append(('KNN', KNN_model))\n",
        "models.append(('NB', GN_model))\n",
        "models.append(('SVM-linear', svc_model_linear))\n",
        "models.append(('SVM-poly', svc_model_poly))\n",
        "models.append(('SVM-rbf', svc_model_rbf))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)\n",
        "\tcv_results = model_selection.cross_val_score(model,  X,y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2L-BfgCrNTeI"
      },
      "cell_type": "markdown",
      "source": [
        "> **Accuracy is more for KNN,LR and svm-linear. However the standard deviation is less for svm-linear model.**\n",
        "\n",
        "> **We can tell  svm-linear be a better algorithm for this dataset because of high accuracy and less Standard deviation**"
      ]
    },
    {
      "metadata": {
        "id": "7yYZslv7NTeI"
      },
      "cell_type": "markdown",
      "source": [
        "**We will check with scaled values to see whether there is improvement in model**"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "id": "o2_hS-omNTeI"
      },
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "# prepare models\n",
        "models = []\n",
        "models.append(('LR', LR_model))\n",
        "models.append(('KNN', KNN_model))\n",
        "models.append(('NB', GN_model))\n",
        "models.append(('SVM-linear', svc_model_linear))\n",
        "models.append(('SVM-poly', svc_model_poly))\n",
        "models.append(('SVM-rbf', svc_model_rbf))\n",
        "# evaluate each model in turn\n",
        "results = []\n",
        "names = []\n",
        "scoring = 'accuracy'\n",
        "for name, model in models:\n",
        "\tkfold = model_selection.KFold(n_splits=10, random_state=seed,shuffle=True)\n",
        "\tcv_results = model_selection.cross_val_score(model,X_Scaled,y, cv=kfold, scoring=scoring)\n",
        "\tresults.append(cv_results)\n",
        "\tnames.append(name)\n",
        "\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
        "\tprint(msg)\n",
        "# boxplot algorithm comparison\n",
        "fig = plt.figure()\n",
        "fig.suptitle('Algorithm Comparison')\n",
        "ax = fig.add_subplot(111)\n",
        "plt.boxplot(results)\n",
        "ax.set_xticklabels(names)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cYhG9sACNTeJ"
      },
      "cell_type": "markdown",
      "source": [
        "**When the scaled values are used instead of normal values Logistic regression is performing well.**\n",
        "\n",
        "**Logistic Regression gives 81% accuracy with little standard deviation.**"
      ]
    },
    {
      "metadata": {
        "id": "Cy7WRL-VNTeJ"
      },
      "cell_type": "markdown",
      "source": [
        "# **6.Conclusion and improvisation:**"
      ]
    },
    {
      "metadata": {
        "id": "enXLuaVBNTeJ"
      },
      "cell_type": "markdown",
      "source": [
        "> **All the variables has significant effect on target class**\n",
        "\n",
        "> **class belongs to type_s has higher mean value for alomst all variables**\n",
        "\n",
        "> **Class belongs to normal has lower values for all variables**\n",
        "\n",
        "> **For almost all variables the distribution is normal**\n",
        "\n",
        "> **For Knn, k=13 we are getting balanced train and test error**\n",
        "\n",
        "> **We can use KNN as a final model because of balanced train and test error also the recall and precision values are good**\n",
        "\n",
        "> **Clear description on each variables may help to understand problem statement better because of medical domain**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "Patients Condition Prediction Model",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}